{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trieuduongle/DVD-GAN/blob/kth/Train%20With%20KTH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLrjGVvQWNxH",
        "outputId": "05c5c114-dc66-41aa-f99f-df3bb973a204"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQ8IXIA9WeV0",
        "outputId": "c5eb8f1f-9bdf-46f8-f233-1ff5c396c335"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/drive/My Drive/Duong/DVD-GAN'...\n",
            "remote: Enumerating objects: 687, done.\u001b[K\n",
            "remote: Counting objects: 100% (146/146), done.\u001b[K\n",
            "remote: Compressing objects: 100% (61/61), done.\u001b[K\n",
            "remote: Total 687 (delta 108), reused 102 (delta 85), pack-reused 541\u001b[K\n",
            "Receiving objects: 100% (687/687), 232.75 KiB | 1.30 MiB/s, done.\n",
            "Resolving deltas: 100% (426/426), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/trieuduongle/DVD-GAN.git '/content/drive/My Drive/Duong/DVD-GAN'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snonURDKWpwk",
        "outputId": "43a0f973-aa45-48e3-e2c6-559cc54dce15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Duong/DVD-GAN\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/drive/My Drive/Duong/DVD-GAN'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  !git config --global user.email \"duongbk1602@gmail.com\"\n",
        "  !git config --global user.name \"Duong Le\""
      ],
      "metadata": {
        "id": "sKPD_fVPGdej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VyuC_ecGWmcU",
        "outputId": "66394573-cd9d-4d51-d0ab-dea55fdc1a1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "M\tscripts/data_prepare.sh\n",
            "M\tscripts/download_annotations.sh\n",
            "M\tscripts/download_dataset.sh\n",
            "M\tscripts/train_model.sh\n",
            "M\tutils/eval_hmdb51.py\n",
            "M\tutils/eval_kinetics.py\n",
            "M\tutils/eval_ucf101.py\n",
            "M\tutils/n_frames_ucf101_hmdb51.py\n",
            "M\tutils/video_jpg_ucf101_hmdb51.py\n",
            "Already on 'kth'\n",
            "Your branch is up to date with 'origin/kth'.\n",
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "!git fetch origin && git checkout kth && git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OisZLDW7vZ_Q",
        "outputId": "05ead58f-4927-4347-b5b4-0be20e1e7e48"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A100-SXM4-40GB'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.device_count()\n",
        "torch.cuda.is_available()\n",
        "torch.cuda.current_device()\n",
        "torch.cuda.device(0)\n",
        "torch.cuda.get_device_name(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvsZ3mzo9BxB"
      },
      "source": [
        "#Trainning with Moving MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTqCwjZEvkwi",
        "outputId": "bd010b7b-4d81-455a-a631-da4ef8ea1b56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects:  25% (1/4)\u001b[K\rremote: Counting objects:  50% (2/4)\u001b[K\rremote: Counting objects:  75% (3/4)\u001b[K\rremote: Counting objects: 100% (4/4)\u001b[K\rremote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (4/4), 387 bytes | 0 bytes/s, done.\n",
            "From https://github.com/trieuduongle/DVD-GAN\n",
            "   21206f2..64e293f  kth        -> origin/kth\n",
            "Updating 21206f2..64e293f\n",
            "Fast-forward\n",
            " Dataloader/dataloader_kth.py | 3 \u001b[32m+\u001b[m\u001b[31m--\u001b[m\n",
            " 1 file changed, 1 insertion(+), 2 deletions(-)\n"
          ]
        }
      ],
      "source": [
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KqQEKFi0jG9",
        "outputId": "f7442927-62cb-4803-e3a1-0535d83a8ec7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hickle==5.0.2\n",
            "  Downloading hickle-5.0.2-py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.9/107.9 KB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboardX==2.5.1\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 KB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy!=1.20,>=1.8 in /usr/local/lib/python3.8/dist-packages (from hickle==5.0.2->-r requirements.txt (line 1)) (1.21.6)\n",
            "Requirement already satisfied: h5py>=2.10.0 in /usr/local/lib/python3.8/dist-packages (from hickle==5.0.2->-r requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX==2.5.1->-r requirements.txt (line 2)) (3.19.6)\n",
            "Installing collected packages: tensorboardX, hickle\n",
            "Successfully installed hickle-5.0.2 tensorboardX-2.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PujfUpHsItgS",
        "outputId": "6a96634b-3326-480c-a3ad-f4a224913ea1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model = dvd-gan\n",
            "adv_loss = mse\n",
            "imsize = 128\n",
            "g_num = 5\n",
            "g_chn = 32\n",
            "z_dim = 120\n",
            "ds_chn = 32\n",
            "dt_chn = 32\n",
            "g_conv_dim = 64\n",
            "d_conv_dim = 64\n",
            "lambda_gp = 10\n",
            "lr_schr = onecycle\n",
            "version = \n",
            "total_epoch = 20\n",
            "d_iters = 1\n",
            "g_iters = 1\n",
            "batch_size = 16\n",
            "num_workers = 4\n",
            "g_lr = 0.01\n",
            "ds_lr = 0.01\n",
            "dt_lr = 0.01\n",
            "lr_decay = 0.9999\n",
            "beta1 = 0.0\n",
            "beta2 = 0.9\n",
            "pretrained_model = None\n",
            "train = True\n",
            "parallel = False\n",
            "gpus = ['0']\n",
            "dataset = ucf101\n",
            "use_tensorboard = True\n",
            "n_class = 101\n",
            "k_sample = 64\n",
            "n_frames = 24\n",
            "test_batch_size = 8\n",
            "image_path = ./data\n",
            "log_path = ./kth_logs\n",
            "model_save_path = ./kth_models\n",
            "sample_path = ./kth_samples\n",
            "interpolate_path = ./interpolate\n",
            "log_epoch = 1\n",
            "sample_epoch = 1\n",
            "model_save_epoch = 5\n",
            "norm_value = 255\n",
            "no_mean_norm = True\n",
            "std_norm = False\n",
            "mean_dataset = activitynet\n",
            "root_path = /tmp4/potter/UCF101\n",
            "video_path = videos_jpeg\n",
            "annotation_path = annotation/ucf101_01.json\n",
            "train_crop = corner\n",
            "sample_size = 64\n",
            "initial_scale = 1.0\n",
            "n_scales = 5\n",
            "scale_step = 0.84089641525\n",
            "in_shape = [10, 1, 64, 64]\n",
            "image_channels = 1\n",
            "hid_S = 64\n",
            "hid_T = 256\n",
            "N_S = 4\n",
            "N_T = 8\n",
            "groups = 4\n",
            "pre_seq_length = 10\n",
            "aft_seq_length = 20\n",
            "lambda_d_s = 0.005\n",
            "lambda_d_t = 0.005\n",
            "val_batch_size = 16\n",
            "data_root = /content/drive/My Drive/Duong/datasets/kth\n",
            "dataname = kth\n",
            "loading test data\n",
            "loaded test_set\n",
            "name train_data_0_sample_2000_gzip.hkl\n",
            "loading data at /content/drive/My Drive/Duong/datasets/kth/train_data_0_sample_2000_gzip.hkl\n",
            "loaded train_set\n",
            "============================== \n",
            "Build_model...\n",
            "using VanillaConv 2d\n",
            "using VanillaConv 2d\n",
            "using VanillaConv 2d\n",
            "using VanillaConv 2d\n",
            "using VanillaConv 2d\n",
            "using VanillaConv 2d\n",
            "using VanillaConv 3d\n",
            "using VanillaConv 3d\n",
            "using VanillaConv 3d\n",
            "using VanillaConv 3d\n",
            "using VanillaConv 3d\n",
            "using VanillaConv 3d\n",
            "============================== \n",
            "Start training from epoch 1...\n",
            "ds_loss: 0.486002386, dt_loss: 0.515211880, g_s_loss: 0.181822583, g_t_loss: 0.280246735, g_loss: 0.056120656, non_g_loss: 0.053810310:   1% 36/3750 [00:35<1:01:29,  1.01it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 88, in <module>\n",
            "    main(config)\n",
            "  File \"main.py\", line 67, in main\n",
            "    trainer.train()\n",
            "  File \"/content/drive/MyDrive/Duong/DVD-GAN/trainer.py\", line 251, in train\n",
            "    for batch_x, batch_y in train_pbar:\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tqdm/std.py\", line 1195, in __iter__\n",
            "    for obj in iterable:\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 628, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 1333, in _next_data\n",
            "    return self._process_data(data)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 1359, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/_utils.py\", line 543, in reraise\n",
            "    raise exception\n",
            "RuntimeError: Caught RuntimeError in DataLoader worker process 0.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n",
            "    data = fetcher.fetch(index)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\", line 61, in fetch\n",
            "    return self.collate_fn(data)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/collate.py\", line 265, in default_collate\n",
            "    return collate(batch, collate_fn_map=default_collate_fn_map)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/collate.py\", line 143, in collate\n",
            "    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/collate.py\", line 143, in <listcomp>\n",
            "    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/collate.py\", line 120, in collate\n",
            "    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/collate.py\", line 162, in collate_tensor_fn\n",
            "    out = elem.new(storage).resize_(len(batch), *list(elem.size()))\n",
            "RuntimeError: Trying to resize storage that is not resizable\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python main.py \\\n",
        "  --batch_size 16 \\\n",
        "  --val_batch_size 16 \\\n",
        "  --adv_loss mse \\\n",
        "  --gpus 0 \\\n",
        "  --use_tensorboard True \\\n",
        "  --num_workers 4 \\\n",
        "  --dataname 'kth' \\\n",
        "  --data_root '/content/drive/My Drive/Duong/datasets/kth' \\\n",
        "  --total_epoch 20 \\\n",
        "  --sample_epoch 1 \\\n",
        "  --model_save_epoch 5 \\\n",
        "  --lr_schr onecycle \\\n",
        "  --g_lr 0.01 \\\n",
        "  --ds_lr 0.01 \\\n",
        "  --dt_lr 0.01 \\\n",
        "  --hid_S 64 \\\n",
        "  --hid_T 256 \\\n",
        "  --N_S 4 \\\n",
        "  --N_T 8 \\\n",
        "  --pre_seq_length 10 \\\n",
        "  --aft_seq_length 20 \\\n",
        "  --log_path './kth_logs' \\\n",
        "  --sample_path './kth_samples' \\\n",
        "  --model_save_path './kth_models'"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}